{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yevgenm/face_recognition/blob/main/facial_recognition_ai_python_with_comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preliminaries"
      ],
      "metadata": {
        "id": "UqNpNL9YdW_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AstQdmx7ecwk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Suppress the output of all commands in this cell.\n",
        "\n",
        "%mkdir yearbook\n",
        "# Create a 'yearbook' directory.\n",
        "\n",
        "%cd yearbook\n",
        "# Change current directory to 'yearbook'.\n",
        "\n",
        "!pip install --upgrade --no-cache-dir gdown\n",
        "# Install (or upgrades) 'gdown' library, to download files from Google Drive.\n",
        "\n",
        "!gdown --id \"1NHT8NN8ClBEnUC5VqkP3wr2KhyiIQzyU\"\n",
        "# Download a file from Google Drive using its ID.\n",
        "\n",
        "!unzip PHfiles.zip\n",
        "# Extract the contents of 'PHfiles.zip'.\n",
        "\n",
        "%mkdir images\n",
        "# Create an 'images' directory.\n",
        "\n",
        "!pip install PyMuPDF\n",
        "# Install PyMuPDF library for PDF processing.\n",
        "\n",
        "!pip install dlib\n",
        "# Install dlib library for image processing and face detection.\n",
        "\n",
        "!pip install DeepFace\n",
        "# Install DeepFace library for facial recognition and analysis.\n",
        "\n",
        "import os, shutil, fitz, cv2, numpy as np, pandas as pd, dlib, tensorflow as tf\n",
        "# Import various libraries for file handling, vision, and machine learning.\n",
        "\n",
        "from os.path import dirname, join\n",
        "# Import functions for working with file paths.\n",
        "\n",
        "from deepface import DeepFace\n",
        "# Import DeepFace for face analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PDF Conversion"
      ],
      "metadata": {
        "id": "5D4NGWwSdagp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhGzknifXosP"
      },
      "outputs": [],
      "source": [
        "path = r'./'\n",
        "# Set the local 'path' variable to the current directory.\n",
        "\n",
        "pdfs = [f for f in os.listdir(path) if f.endswith('.pdf')]\n",
        "# Create a list of all PDF files in the current directory.\n",
        "\n",
        "for pdf in pdfs:\n",
        "# Loop through each PDF file in the list.\n",
        "\n",
        "    os.chdir(os.path.join('./images'))\n",
        "    # Change directory to the 'images' folder.\n",
        "\n",
        "    os.mkdir((pdf.split(\".\")[0]))\n",
        "    # Create a folder named after the PDF (without the extension).\n",
        "\n",
        "    newdir = (os.path.join('./images/' + os.path.join(pdf.split(\".\")[0])))\n",
        "    # Define the full path for the new folder.\n",
        "\n",
        "    os.chdir(\"..\")\n",
        "    # Move back to the previous directory (one level higher).\n",
        "\n",
        "    print(\"Now copying images into \" + (newdir))\n",
        "    # Print a message saying where images will be copied.\n",
        "\n",
        "    shutil.copy(pdf, newdir)\n",
        "    # Copy the current PDF to the newly created folder.\n",
        "\n",
        "    os.chdir(newdir)\n",
        "    # Change directory to the new folder.\n",
        "\n",
        "    doc = fitz.open(pdf)\n",
        "    # Open the PDF file using PyMuPDF (or 'fitz', when used from inside Python).\n",
        "\n",
        "    for page in doc:\n",
        "    # Loop through each page in the PDF.\n",
        "\n",
        "        pix = page.get_pixmap()\n",
        "        # Generate a pixmap (image) of the current page.\n",
        "\n",
        "        pix.save(\"page-%i.png\" % page.number)\n",
        "        # Save the page as a PNG image with the page number in the file name.\n",
        "\n",
        "    os.chdir(os.path.dirname(os.getcwd()))\n",
        "    # Move back to the parent directory.\n",
        "\n",
        "    os.chdir(\"..\")\n",
        "    # Move back one more directory."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Object Detection and Facial Recognition: Code"
      ],
      "metadata": {
        "id": "2jYcnBWodq7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92YhmH4AhFR1"
      },
      "outputs": [],
      "source": [
        "path = r'./'\n",
        "# Set the local 'path' variable to the current directory.\n",
        "\n",
        "os.chdir(os.path.join(path + 'images'))\n",
        "# Change current directory to 'images'.\n",
        "\n",
        "dirs = os.listdir(path)\n",
        "# List all directories and files in the base directory ('path').\n",
        "\n",
        "for dir in dirs:\n",
        "# Loop through each directory in the 'path'.\n",
        "\n",
        "    os.chdir(os.path.join(path + dir))\n",
        "    # Change current directory to the one being processed.\n",
        "\n",
        "    pngs = [f for f in os.listdir(path) if f.endswith('.png')]\n",
        "    # Create a list of all PNG files in the current directory.\n",
        "\n",
        "    if not os.path.exists((dir) + ' faces'):\n",
        "    # Check if 'faces' folder exists in the current directory.\n",
        "\n",
        "        print(\"New 'faces' directory created in \" + (dir) + \" folder\")\n",
        "        # Print a message about creating a new 'faces' folder.\n",
        "\n",
        "        os.makedirs((dir) + ' faces')\n",
        "        # Create a 'faces' folder in the current directory.\n",
        "\n",
        "        count = 0\n",
        "        # Initialize a counter for face images.\n",
        "\n",
        "        for png in pngs:\n",
        "        # Loop through each PNG file.\n",
        "\n",
        "            image = cv2.imread(png)\n",
        "            # Read the image file.\n",
        "\n",
        "            greyscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            # Convert the image to grayscale.\n",
        "\n",
        "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "            # Load the Haar Cascade model for face detection.\n",
        "\n",
        "            detected_faces = face_cascade.detectMultiScale(image=greyscale_image, scaleFactor=1.9, minNeighbors=4)\n",
        "            # Detect faces in the grayscale image.\n",
        "\n",
        "            count = 0\n",
        "            # Reset the counter (for each directory).\n",
        "\n",
        "            for (x, y, w, h) in detected_faces:\n",
        "            # Loop through the coordinates of each detected face.\n",
        "\n",
        "                try:\n",
        "                # A statement to prevent code execution from stopping in case of errors.\n",
        "\n",
        "                    xpadding = 20\n",
        "                    # Set horizontal padding around the face.\n",
        "\n",
        "                    ypadding = 40\n",
        "                    # Set vertical padding around the face.\n",
        "\n",
        "                    crop_face = image[y-ypadding : y+h+ypadding, x-xpadding : x+w+xpadding]\n",
        "                    # Crop the face area with padding.\n",
        "\n",
        "                    count += 1\n",
        "                    # Increment the face counter.\n",
        "\n",
        "                    face = cv2.rectangle(crop_face, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "                    # Draw a rectangle around the detected face.\n",
        "\n",
        "                    cv2.imwrite(path + (dir) + ' faces/' + str(count) + '_' + png, face)\n",
        "                    # Save the cropped face image to the 'faces' folder.\n",
        "\n",
        "                except (Exception):\n",
        "                # Handle any errors that occur.\n",
        "\n",
        "                    print(\"An error happened\")\n",
        "                    # Print an error message.\n",
        "\n",
        "                    continue\n",
        "                    # Skip to the next face if an error occurs.\n",
        "\n",
        "            os.remove(os.path.join(path, png))\n",
        "            # Remove the original PNG file after processing.\n",
        "\n",
        "    os.chdir(\"..\")\n",
        "    # Move back to the parent directory after processing the current directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Identify Smiles: Code"
      ],
      "metadata": {
        "id": "ysjW9Atvd00g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26ben4VqkGwd"
      },
      "outputs": [],
      "source": [
        "%cd ..\n",
        "# Move to the parent directory.\n",
        "\n",
        "number_smiles = 0\n",
        "# Initialize the smile counter.\n",
        "\n",
        "smile_counts = []\n",
        "# Create a list to store smile percentages.\n",
        "\n",
        "number_nonsmiles = 0\n",
        "# Initialize the non-smile counter.\n",
        "\n",
        "nonsmile_counts = []\n",
        "# Create a list to store non-smile percentages.\n",
        "\n",
        "num_errors = 0\n",
        "# Initialize the error counter.\n",
        "\n",
        "error_counts = []\n",
        "# Create a list to store error percentages.\n",
        "\n",
        "pngs = []\n",
        "# Create a list to store paths of PNG files.\n",
        "\n",
        "file_count = 0\n",
        "# Initialize the counter for PNG files per directory.\n",
        "\n",
        "file_count_list = []\n",
        "# Create a list to store file counts for each directory.\n",
        "\n",
        "years = ['1911', '1921', '1931', '1941', '1951', '1961']\n",
        "# Define a list of years representing the dataset folders.\n",
        "\n",
        "for year in years:\n",
        "# Loop through each year in the dataset.\n",
        "\n",
        "    path = r'./images' + '/' + year\n",
        "    # Define the base path for each year.\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "    # Walk through the directory tree for the given year.\n",
        "\n",
        "        for dir in dirs:\n",
        "        # Loop through each subdirectory.\n",
        "\n",
        "            path = path + '/' + (year + ' faces')\n",
        "            # Append the 'faces' directory path for the current year.\n",
        "\n",
        "            if (file_count != 0):\n",
        "            # Check if any files have already been found.\n",
        "\n",
        "                file_count_list.append(file_count)\n",
        "                # Store the count of PNG files for this directory.\n",
        "\n",
        "            file_count = 0\n",
        "            # Reset the file count for the next directory.\n",
        "\n",
        "            for f in os.listdir(path):\n",
        "            # Loop through each file in the directory.\n",
        "\n",
        "                if f.endswith('.png'):\n",
        "                # Check if the file is a PNG.\n",
        "\n",
        "                    pngs.append(path + '/' + f)\n",
        "                    # Add the file path to the PNG list.\n",
        "\n",
        "                    file_count = file_count + 1\n",
        "                    # Increment the file counter.\n",
        "\n",
        "file_count_list.append(file_count)\n",
        "# Append the final file count after processing all directories.\n",
        "\n",
        "total_loops = 0\n",
        "# Initialize the loop counter for processed images.\n",
        "\n",
        "count = 0\n",
        "# Initialize the counter for files in the current year.\n",
        "\n",
        "iterator = 0\n",
        "# Initialize an iterator for file count list.\n",
        "\n",
        "for png in pngs:\n",
        "# Loop through each PNG file in the list.\n",
        "\n",
        "    try:\n",
        "        total_loops = total_loops + 1\n",
        "        # Increment the loop counter.\n",
        "\n",
        "        count = count + 1\n",
        "        # Increment the file counter for the current directory.\n",
        "\n",
        "        if (count != (file_count_list[iterator] + 1)):\n",
        "        # Check if the count matches the expected number of files in the current directory.\n",
        "\n",
        "            demography = DeepFace.analyze(png, actions=['emotion'])\n",
        "            # Analyze the PNG file for emotions using DeepFace.\n",
        "\n",
        "            print(demography)\n",
        "            # Print the analysis results.\n",
        "\n",
        "            if(demography[0]['dominant_emotion'] == 'happy'):\n",
        "            # Check if the dominant emotion is happiness.\n",
        "\n",
        "                number_smiles = number_smiles + 1\n",
        "                # Increment the smile counter.\n",
        "\n",
        "            else:\n",
        "                number_nonsmiles = number_nonsmiles + 1\n",
        "                # Increment the non-smile counter.\n",
        "\n",
        "        else:\n",
        "            count = count - 1\n",
        "            # Adjust count for the current directory.\n",
        "\n",
        "            smile_counts.append(number_smiles / count)\n",
        "            # Append the smile percentage for the directory.\n",
        "\n",
        "            nonsmile_counts.append(number_nonsmiles / count)\n",
        "            # Append the non-smile percentage for the directory.\n",
        "\n",
        "            error_counts.append(num_errors / count)\n",
        "            # Append the error weight for the directory.\n",
        "\n",
        "            number_smiles = 0\n",
        "            # Reset the smile counter for the next directory.\n",
        "\n",
        "            number_nonsmiles = 0\n",
        "            # Reset the non-smile counter for the next directory.\n",
        "\n",
        "            num_errors = 0\n",
        "            # Reset the error counter for the next directory.\n",
        "\n",
        "            iterator = iterator + 1\n",
        "            # Move to the next directory in the iterator.\n",
        "\n",
        "            count = 0\n",
        "            # Reset the count for the next directory.\n",
        "\n",
        "    except (Exception):\n",
        "    # Handle exceptions that occur during analysis.\n",
        "\n",
        "        num_errors = num_errors + 1\n",
        "        # Increment the error counter.\n",
        "\n",
        "        print(\"An error happened\")\n",
        "        # Print an error message.\n",
        "\n",
        "        continue\n",
        "        # Skip to the next PNG file.\n",
        "\n",
        "smile_counts.append(number_smiles / count)\n",
        "# Append the smile percentage for the last directory.\n",
        "\n",
        "nonsmile_counts.append(number_nonsmiles / count)\n",
        "# Append the non-smile percentage for the last directory.\n",
        "\n",
        "error_counts.append(num_errors / count)\n",
        "# Append the error weight for the last directory.\n",
        "\n",
        "dict = {'Years': years,\n",
        "        'Smiles': smile_counts,\n",
        "        'Non-Smiles': nonsmile_counts,\n",
        "        \"Error Weight\": error_counts}\n",
        "# Create a dictionary to store results for each year.\n",
        "\n",
        "data = pd.DataFrame(dict)\n",
        "# Create a DataFrame from the dictionary.\n",
        "\n",
        "data.to_csv('YearbookOutput.csv', index=False)\n",
        "# Save the results to a CSV file.\n",
        "\n",
        "print(count)\n",
        "# Print the count of the last processed directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download and results"
      ],
      "metadata": {
        "id": "Sa2rV4Hzd5NE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QxBepnRtns50",
        "outputId": "f111e0c8-f555-4687-d930-0645124a534b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4a60c698-c3e1-47d6-ade9-d3c7bc65583f\", \"YearbookOutput.csv\", 264)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "# Import the module to handle file downloads in Google Colab.\n",
        "\n",
        "files.download('YearbookOutput.csv')\n",
        "# Download the CSV file to your local system."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}